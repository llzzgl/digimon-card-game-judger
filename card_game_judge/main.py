# æŠ‘åˆ¶å„ç§è­¦å‘Šä¿¡æ¯
import warnings
import os

# åœ¨å¯¼å…¥å…¶ä»–åº“ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"  # ä½¿ç”¨ Hugging Face é•œåƒ
os.environ["ANONYMIZED_TELEMETRY"] = "False"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# æŠ‘åˆ¶ deprecation è­¦å‘Š
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", message=".*CryptographyDeprecationWarning.*")
warnings.filterwarnings("ignore", message=".*ARC4.*")
warnings.filterwarnings("ignore", message=".*torch.classes.*")

import uvicorn
import argparse
import subprocess
import sys
from pathlib import Path
from typing import Optional, List


def batch_import_files(
    directory: str,
    doc_type: str = "rule",
    tags: str = "",
    file_pattern: str = "*.json",
    title_prefix: str = "",
    title_suffix: str = ""
):
    """
    æ‰¹é‡å¯¼å…¥ç›®å½•ä¸­çš„æ–‡ä»¶åˆ°çŸ¥è¯†åº“
    
    Args:
        directory: æ–‡ä»¶ç›®å½•è·¯å¾„
        doc_type: æ–‡æ¡£ç±»å‹ (rule/ruling/case)
        tags: æ ‡ç­¾ï¼Œé€—å·åˆ†éš”
        file_pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
        title_prefix: ä»æ–‡ä»¶åä¸­ç§»é™¤çš„å‰ç¼€
        title_suffix: ä»æ–‡ä»¶åä¸­ç§»é™¤çš„åç¼€
    """
    from app.vector_store import vector_store
    from app.pdf_processor import extract_text_from_bytes
    from app.models import DocumentType, DocumentMetadata
    
    dir_path = Path(directory)
    if not dir_path.exists():
        print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨ - {directory}")
        return
    
    files = list(dir_path.glob(file_pattern))
    if not files:
        print(f"æœªæ‰¾åˆ°åŒ¹é… {file_pattern} çš„æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶å¾…å¯¼å…¥...")
    
    # è§£ææ–‡æ¡£ç±»å‹
    try:
        dtype = DocumentType(doc_type)
    except ValueError:
        print(f"é”™è¯¯: æ— æ•ˆçš„æ–‡æ¡£ç±»å‹ '{doc_type}'ï¼Œå¯é€‰: rule, ruling, case")
        return
    
    # è§£ææ ‡ç­¾
    tag_list = [t.strip() for t in tags.split(",") if t.strip()]
    
    success_count = 0
    fail_count = 0
    
    for file_path in files:
        try:
            # ç”Ÿæˆæ ‡é¢˜
            title = file_path.stem  # å»æ‰æ‰©å±•å
            if title_prefix and title.startswith(title_prefix):
                title = title[len(title_prefix):]
            if title_suffix and title.endswith(title_suffix):
                title = title[:-len(title_suffix)]
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            content = file_path.read_bytes()
            text = extract_text_from_bytes(content, file_path.name)
            
            if not text.strip():
                print(f"  è·³è¿‡ (æ— å†…å®¹): {file_path.name}")
                fail_count += 1
                continue
            
            # åˆ›å»ºå…ƒæ•°æ®
            metadata = DocumentMetadata(
                doc_type=dtype,
                title=title,
                source=str(file_path),
                tags=tag_list
            )
            
            # æ·»åŠ åˆ°å‘é‡åº“
            result = vector_store.add_document(text, metadata)
            print(f"  âœ“ {title} ({result['chunk_count']} chunks)")
            success_count += 1
            
        except Exception as e:
            print(f"  âœ— {file_path.name}: {e}")
            fail_count += 1
    
    print(f"\nå¯¼å…¥å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å¡ç‰Œæ¸¸æˆæ™ºèƒ½è£åˆ¤")
    parser.add_argument("--mode", type=str, default="web", choices=["web", "streamlit", "api"],
                        help="å¯åŠ¨æ¨¡å¼: web(æ¨è,FastAPI+HTML), streamlit(æ—§UI), api(ä»…API)")
    parser.add_argument("--port", type=int, default=8000, help="ç«¯å£å·")
    
    # æ‰¹é‡å¯¼å…¥å‚æ•°
    parser.add_argument("--batch-import", type=str, metavar="DIR", help="æ‰¹é‡å¯¼å…¥ç›®å½•ä¸­çš„æ–‡ä»¶")
    parser.add_argument("--doc-type", type=str, default="rule", help="æ–‡æ¡£ç±»å‹: rule/ruling/case")
    parser.add_argument("--tags", type=str, default="", help="æ ‡ç­¾ï¼Œé€—å·åˆ†éš”")
    parser.add_argument("--pattern", type=str, default="*.json", help="æ–‡ä»¶åŒ¹é…æ¨¡å¼")
    parser.add_argument("--remove-prefix", type=str, default="", help="ä»æ–‡ä»¶åç§»é™¤çš„å‰ç¼€")
    parser.add_argument("--remove-suffix", type=str, default="", help="ä»æ–‡ä»¶åç§»é™¤çš„åç¼€")
    
    # å…¼å®¹æ—§å‚æ•°
    parser.add_argument("--no_ui", action="store_true", help="(å·²åºŸå¼ƒ) ä½¿ç”¨ --mode api ä»£æ›¿")
    
    args = parser.parse_args()
    
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    
    if args.batch_import:
        # æ‰¹é‡å¯¼å…¥æ¨¡å¼
        batch_import_files(
            directory=args.batch_import,
            doc_type=args.doc_type,
            tags=args.tags,
            file_pattern=args.pattern,
            title_prefix=args.remove_prefix,
            title_suffix=args.remove_suffix
        )
    elif args.no_ui or args.mode == "api":
        # ä»… API æ¨¡å¼
        print(f"ğŸš€ å¯åŠ¨ API æœåŠ¡: http://localhost:{args.port}")
        print(f"ğŸ“– API æ–‡æ¡£: http://localhost:{args.port}/docs")
        uvicorn.run("app.api:app", host="0.0.0.0", port=args.port, reload=False)
    elif args.mode == "streamlit":
        # Streamlit æ¨¡å¼ (æ—§UIï¼Œå¯èƒ½å¡é¡¿)
        print("âš ï¸  Streamlit æ¨¡å¼å¯èƒ½ä¼šå¡é¡¿ï¼Œæ¨èä½¿ç”¨ --mode web")
        ui_path = os.path.join(script_dir, "app", "web_ui.py")
        env = os.environ.copy()
        env["PYTHONWARNINGS"] = "ignore"
        subprocess.run([sys.executable, "-m", "streamlit", "run", 
                       ui_path, "--server.port", str(args.port)], env=env)
    else:
        # é»˜è®¤: FastAPI + HTML å‰ç«¯ (æ¨è)
        print(f"ğŸ´ å¡ç‰Œæ¸¸æˆæ™ºèƒ½è£åˆ¤")
        print(f"ğŸŒ æ‰“å¼€æµè§ˆå™¨è®¿é—®: http://localhost:{args.port}")
        print(f"ğŸ“– API æ–‡æ¡£: http://localhost:{args.port}/docs")
        print(f"â³ é¦–æ¬¡å¯åŠ¨éœ€è¦åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...")
        uvicorn.run("app.api:app", host="0.0.0.0", port=args.port, reload=False)
